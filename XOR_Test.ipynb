{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[0, 0], [1, 1], [0, 1], [1, 0]])\n",
    "\n",
    "Y_train = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, Y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    \n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, Y_batch = X[batch_idx], Y[batch_idx]\n",
    "        \n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "\n",
    "cols = ['# of Hidden Layers', '# of Neurons at HLs','Time Took', 'Training Accuracy', 'Training Loss']\n",
    "\n",
    "# Fixed hyper-parameters\n",
    "epochs = 200\n",
    "batch_size = 2\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ----- Epoch  0  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.33037952\n",
      "\n",
      "  ----- Epoch  1  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.33184898\n",
      "\n",
      "  ----- Epoch  2  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.33384243\n",
      "\n",
      "  ----- Epoch  3  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3362526\n",
      "\n",
      "  ----- Epoch  4  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3381952\n",
      "\n",
      "  ----- Epoch  5  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3405099\n",
      "\n",
      "  ----- Epoch  6  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.34254643\n",
      "\n",
      "  ----- Epoch  7  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.34455657\n",
      "\n",
      "  ----- Epoch  8  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.34677687\n",
      "\n",
      "  ----- Epoch  9  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.34910876\n",
      "\n",
      "  ----- Epoch  10  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3512257\n",
      "\n",
      "  ----- Epoch  11  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3535142\n",
      "\n",
      "  ----- Epoch  12  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.35560417\n",
      "\n",
      "  ----- Epoch  13  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.357696\n",
      "\n",
      "  ----- Epoch  14  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3597788\n",
      "\n",
      "  ----- Epoch  15  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.36202222\n",
      "\n",
      "  ----- Epoch  16  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.36394876\n",
      "\n",
      "  ----- Epoch  17  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.36600828\n",
      "\n",
      "  ----- Epoch  18  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.36815205\n",
      "\n",
      "  ----- Epoch  19  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3703071\n",
      "\n",
      "  ----- Epoch  20  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.37215927\n",
      "\n",
      "  ----- Epoch  21  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3741371\n",
      "\n",
      "  ----- Epoch  22  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.37591422\n",
      "\n",
      "  ----- Epoch  23  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.37769145\n",
      "\n",
      "  ----- Epoch  24  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.37945136\n",
      "\n",
      "  ----- Epoch  25  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.38132942\n",
      "\n",
      "  ----- Epoch  26  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.3831002\n",
      "\n",
      "  ----- Epoch  27  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.38504198\n",
      "\n",
      "  ----- Epoch  28  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.38676015\n",
      "\n",
      "  ----- Epoch  29  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.388441\n",
      "\n",
      "  ----- Epoch  30  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.39031887\n",
      "\n",
      "  ----- Epoch  31  ----\n",
      "\n",
      "Train accuracy:  0.25\n",
      "Train log_loss:  0.39205045\n",
      "\n",
      "  ----- Epoch  32  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.3937974\n",
      "\n",
      "  ----- Epoch  33  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.39541245\n",
      "\n",
      "  ----- Epoch  34  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.3969072\n",
      "\n",
      "  ----- Epoch  35  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.39867732\n",
      "\n",
      "  ----- Epoch  36  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.40022147\n",
      "\n",
      "  ----- Epoch  37  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.40184128\n",
      "\n",
      "  ----- Epoch  38  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.40349516\n",
      "\n",
      "  ----- Epoch  39  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.40517688\n",
      "\n",
      "  ----- Epoch  40  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.40659395\n",
      "\n",
      "  ----- Epoch  41  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.40819752\n",
      "\n",
      "  ----- Epoch  42  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.40969896\n",
      "\n",
      "  ----- Epoch  43  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.41128513\n",
      "\n",
      "  ----- Epoch  44  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.41276067\n",
      "\n",
      "  ----- Epoch  45  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.41422734\n",
      "\n",
      "  ----- Epoch  46  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.41573054\n",
      "\n",
      "  ----- Epoch  47  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.4173\n",
      "\n",
      "  ----- Epoch  48  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.41873825\n",
      "\n",
      "  ----- Epoch  49  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.42035526\n",
      "\n",
      "  ----- Epoch  50  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.42184854\n",
      "\n",
      "  ----- Epoch  51  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.4232708\n",
      "\n",
      "  ----- Epoch  52  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.42487118\n",
      "\n",
      "  ----- Epoch  53  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.42633644\n",
      "\n",
      "  ----- Epoch  54  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.42783055\n",
      "\n",
      "  ----- Epoch  55  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.42931134\n",
      "\n",
      "  ----- Epoch  56  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.4309029\n",
      "\n",
      "  ----- Epoch  57  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.43228373\n",
      "\n",
      "  ----- Epoch  58  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.43373424\n",
      "\n",
      "  ----- Epoch  59  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.43531233\n",
      "\n",
      "  ----- Epoch  60  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.43689308\n",
      "\n",
      "  ----- Epoch  61  ----\n",
      "\n",
      "Train accuracy:  0.5\n",
      "Train log_loss:  0.43830308\n",
      "\n",
      "  ----- Epoch  62  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4398598\n",
      "\n",
      "  ----- Epoch  63  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.44142434\n",
      "\n",
      "  ----- Epoch  64  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.44285494\n",
      "\n",
      "  ----- Epoch  65  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.44438067\n",
      "\n",
      "  ----- Epoch  66  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4457863\n",
      "\n",
      "  ----- Epoch  67  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.44733533\n",
      "\n",
      "  ----- Epoch  68  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.44889617\n",
      "\n",
      "  ----- Epoch  69  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.45043516\n",
      "\n",
      "  ----- Epoch  70  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.45195574\n",
      "\n",
      "  ----- Epoch  71  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.45345414\n",
      "\n",
      "  ----- Epoch  72  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.45483884\n",
      "\n",
      "  ----- Epoch  73  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4561829\n",
      "\n",
      "  ----- Epoch  74  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4576429\n",
      "\n",
      "  ----- Epoch  75  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.45904553\n",
      "\n",
      "  ----- Epoch  76  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.46035886\n",
      "\n",
      "  ----- Epoch  77  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.46184117\n",
      "\n",
      "  ----- Epoch  78  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.46336848\n",
      "\n",
      "  ----- Epoch  79  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4647651\n",
      "\n",
      "  ----- Epoch  80  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4662628\n",
      "\n",
      "  ----- Epoch  81  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.46772912\n",
      "\n",
      "  ----- Epoch  82  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.46913415\n",
      "\n",
      "  ----- Epoch  83  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.47063908\n",
      "\n",
      "  ----- Epoch  84  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.47213107\n",
      "\n",
      "  ----- Epoch  85  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.47352526\n",
      "\n",
      "  ----- Epoch  86  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4749423\n",
      "\n",
      "  ----- Epoch  87  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.47648573\n",
      "\n",
      "  ----- Epoch  88  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.47791997\n",
      "\n",
      "  ----- Epoch  89  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.47935316\n",
      "\n",
      "  ----- Epoch  90  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4806955\n",
      "\n",
      "  ----- Epoch  91  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.48177904\n",
      "\n",
      "  ----- Epoch  92  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.48287836\n",
      "\n",
      "  ----- Epoch  93  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.48407617\n",
      "\n",
      "  ----- Epoch  94  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.48543176\n",
      "\n",
      "  ----- Epoch  95  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.48673534\n",
      "\n",
      "  ----- Epoch  96  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.48792973\n",
      "\n",
      "  ----- Epoch  97  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4891476\n",
      "\n",
      "  ----- Epoch  98  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.49039638\n",
      "\n",
      "  ----- Epoch  99  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4915555\n",
      "\n",
      "  ----- Epoch  100  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.49287793\n",
      "\n",
      "  ----- Epoch  101  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.49423954\n",
      "\n",
      "  ----- Epoch  102  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4954665\n",
      "\n",
      "  ----- Epoch  103  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.4966336\n",
      "\n",
      "  ----- Epoch  104  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.49791566\n",
      "\n",
      "  ----- Epoch  105  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.49934298\n",
      "\n",
      "  ----- Epoch  106  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.50065076\n",
      "\n",
      "  ----- Epoch  107  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5016763\n",
      "\n",
      "  ----- Epoch  108  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5027761\n",
      "\n",
      "  ----- Epoch  109  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5039727\n",
      "\n",
      "  ----- Epoch  110  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.505174\n",
      "\n",
      "  ----- Epoch  111  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.50644326\n",
      "\n",
      "  ----- Epoch  112  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5078894\n",
      "\n",
      "  ----- Epoch  113  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.509148\n",
      "\n",
      "  ----- Epoch  114  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5102988\n",
      "\n",
      "  ----- Epoch  115  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.51159\n",
      "\n",
      "  ----- Epoch  116  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.51286554\n",
      "\n",
      "  ----- Epoch  117  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5141413\n",
      "\n",
      "  ----- Epoch  118  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.51536286\n",
      "\n",
      "  ----- Epoch  119  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.51667285\n",
      "\n",
      "  ----- Epoch  120  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5179624\n",
      "\n",
      "  ----- Epoch  121  ----\n",
      "\n",
      "Train accuracy:  0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train log_loss:  0.5193223\n",
      "\n",
      "  ----- Epoch  122  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.52083784\n",
      "\n",
      "  ----- Epoch  123  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5223236\n",
      "\n",
      "  ----- Epoch  124  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5239208\n",
      "\n",
      "  ----- Epoch  125  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.525513\n",
      "\n",
      "  ----- Epoch  126  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5270349\n",
      "\n",
      "  ----- Epoch  127  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5287037\n",
      "\n",
      "  ----- Epoch  128  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.5304115\n",
      "\n",
      "  ----- Epoch  129  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.53199106\n",
      "\n",
      "  ----- Epoch  130  ----\n",
      "\n",
      "Train accuracy:  0.75\n",
      "Train log_loss:  0.53365004\n",
      "\n",
      "  ----- Epoch  131  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.53539234\n",
      "\n",
      "  ----- Epoch  132  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5369963\n",
      "\n",
      "  ----- Epoch  133  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.53863287\n",
      "\n",
      "  ----- Epoch  134  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.54047966\n",
      "\n",
      "  ----- Epoch  135  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5422028\n",
      "\n",
      "  ----- Epoch  136  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.54391026\n",
      "\n",
      "  ----- Epoch  137  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.54581165\n",
      "\n",
      "  ----- Epoch  138  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5477288\n",
      "\n",
      "  ----- Epoch  139  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5498352\n",
      "\n",
      "  ----- Epoch  140  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.55197245\n",
      "\n",
      "  ----- Epoch  141  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.55426186\n",
      "\n",
      "  ----- Epoch  142  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5563687\n",
      "\n",
      "  ----- Epoch  143  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5586552\n",
      "\n",
      "  ----- Epoch  144  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5608994\n",
      "\n",
      "  ----- Epoch  145  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.56257886\n",
      "\n",
      "  ----- Epoch  146  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5643438\n",
      "\n",
      "  ----- Epoch  147  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.566239\n",
      "\n",
      "  ----- Epoch  148  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.56808305\n",
      "\n",
      "  ----- Epoch  149  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.570054\n",
      "\n",
      "  ----- Epoch  150  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.57214403\n",
      "\n",
      "  ----- Epoch  151  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5738877\n",
      "\n",
      "  ----- Epoch  152  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5757635\n",
      "\n",
      "  ----- Epoch  153  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5778408\n",
      "\n",
      "  ----- Epoch  154  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5798136\n",
      "\n",
      "  ----- Epoch  155  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5817931\n",
      "\n",
      "  ----- Epoch  156  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5839701\n",
      "\n",
      "  ----- Epoch  157  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.586155\n",
      "\n",
      "  ----- Epoch  158  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5880352\n",
      "\n",
      "  ----- Epoch  159  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.58986944\n",
      "\n",
      "  ----- Epoch  160  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.591994\n",
      "\n",
      "  ----- Epoch  161  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5940479\n",
      "\n",
      "  ----- Epoch  162  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.59602374\n",
      "\n",
      "  ----- Epoch  163  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.5982374\n",
      "\n",
      "  ----- Epoch  164  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.60027605\n",
      "\n",
      "  ----- Epoch  165  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6023351\n",
      "\n",
      "  ----- Epoch  166  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.60436577\n",
      "\n",
      "  ----- Epoch  167  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.60641336\n",
      "\n",
      "  ----- Epoch  168  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.608431\n",
      "\n",
      "  ----- Epoch  169  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.61052775\n",
      "\n",
      "  ----- Epoch  170  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6125291\n",
      "\n",
      "  ----- Epoch  171  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.61447406\n",
      "\n",
      "  ----- Epoch  172  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6167099\n",
      "\n",
      "  ----- Epoch  173  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6188127\n",
      "\n",
      "  ----- Epoch  174  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.62090987\n",
      "\n",
      "  ----- Epoch  175  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.62297\n",
      "\n",
      "  ----- Epoch  176  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.624822\n",
      "\n",
      "  ----- Epoch  177  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.627048\n",
      "\n",
      "  ----- Epoch  178  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.62904555\n",
      "\n",
      "  ----- Epoch  179  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6311717\n",
      "\n",
      "  ----- Epoch  180  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.63331646\n",
      "\n",
      "  ----- Epoch  181  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6353723\n",
      "\n",
      "  ----- Epoch  182  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.63745993\n",
      "\n",
      "  ----- Epoch  183  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.63959247\n",
      "\n",
      "  ----- Epoch  184  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6416815\n",
      "\n",
      "  ----- Epoch  185  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6438818\n",
      "\n",
      "  ----- Epoch  186  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.64582735\n",
      "\n",
      "  ----- Epoch  187  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.64791435\n",
      "\n",
      "  ----- Epoch  188  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6502745\n",
      "\n",
      "  ----- Epoch  189  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6524194\n",
      "\n",
      "  ----- Epoch  190  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6546144\n",
      "\n",
      "  ----- Epoch  191  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.656782\n",
      "\n",
      "  ----- Epoch  192  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6589519\n",
      "\n",
      "  ----- Epoch  193  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6613001\n",
      "\n",
      "  ----- Epoch  194  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.66318744\n",
      "\n",
      "  ----- Epoch  195  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.66531205\n",
      "\n",
      "  ----- Epoch  196  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6674877\n",
      "\n",
      "  ----- Epoch  197  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.66942585\n",
      "\n",
      "  ----- Epoch  198  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6717514\n",
      "\n",
      "  ----- Epoch  199  ----\n",
      "\n",
      "Train accuracy:  1.0\n",
      "Train log_loss:  0.6740175\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "n_hidden = 6\n",
    "n_out = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(2)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, 2), name = \"X\")\n",
    "Y = tf.placeholder(tf.int32, shape = (None), name = \"Y\")\n",
    "\n",
    "with tf.name_scope(\"MLP\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, name = \"hidden_1\", activation = tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, name = \"hidden_2\", activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_out, name = \"output\")\n",
    "    y_prob = tf.nn.softmax(logits)\n",
    "    \n",
    "with tf.name_scope(\"Loss\"):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = Y, logits = logits)\n",
    "    loss = tf.reduce_mean(cross_entropy, name = \"Loss\")\n",
    "    log_loss = -tf.math.log(loss)\n",
    "\n",
    "with tf.name_scope(\"Train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope('Eval'):\n",
    "    correct = tf.nn.in_top_k(logits, Y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "his_acc = []\n",
    "his_log_loss = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(epochs):\n",
    "        print('\\n  ----- Epoch ', epoch, ' ----\\n')\n",
    "        for X_batch, Y_batch in shuffle_batch(X_train, Y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict = {X: X_batch, Y: Y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict = {X: X_train, Y: Y_train})\n",
    "        log_loss_train = log_loss.eval(feed_dict = {X: X_train, Y: Y_train})\n",
    "        y_pred = sess.run(y_prob, feed_dict = {X: X_train})\n",
    "        \n",
    "        his_acc.append(acc_train)\n",
    "        his_log_loss.append(log_loss_train)\n",
    "        print('Train accuracy: ', acc_train)\n",
    "        print('Train log_loss: ', log_loss_train)\n",
    "        \n",
    "end = datetime.datetime.now()\n",
    "run_time = end - start\n",
    "\n",
    "metrics['Model 1'] = [2, n_hidden, run_time, acc_train, log_loss_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model 1': [2,\n",
       "  6,\n",
       "  datetime.timedelta(seconds=2, microseconds=140768),\n",
       "  1.0,\n",
       "  0.6740175]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x230996530b8>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(his_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23099b29860>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(his_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_out = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "temp_out == Y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
